{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c52f37-e1a9-4885-a88b-8e0d4f970afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select answer language:\n",
      "1 = Thai\n",
      "2 = English\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language (1/2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer language set to: Thai\n",
      "\n",
      "Choose mode:\n",
      "1 = Ingest (save memory)\n",
      "2 = Ask (question)\n",
      "Type /bye to exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode (1/2):  1\n",
      "Context to save:  ‡∏û‡∏µ‡∏û‡∏µ ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏£‡∏¥‡∏á‡∏ä‡∏∑‡πà‡∏≠ ‡∏®‡∏±‡∏Å‡∏¢‡πå‡∏®‡∏£‡∏ì‡πå\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen table: users\n",
      "Saved ‚úÖ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode (1/2):  2\n",
      "Question:  ‡∏û‡∏µ‡∏û‡∏µ‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in table: users\n",
      "\n",
      "Answer:\n",
      "‡∏û‡∏µ‡∏û‡∏µ‡∏Ñ‡∏∑‡∏≠ nickname ‡∏Ç‡∏≠‡∏á ‡∏®‡∏±‡∏Å‡∏¢‡πå‡∏®‡∏£‡∏ì‡πå\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"rag_db\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "}\n",
    "\n",
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "CHAT_MODEL = \"deepseek-r1\"\n",
    "EMBED_DIM = 768\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# DB CONNECTION\n",
    "# =========================================================\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Enable pgvector\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# DB UTILITIES\n",
    "# =========================================================\n",
    "def get_all_tables():\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'public'\n",
    "          AND table_type = 'BASE TABLE'\n",
    "        ORDER BY table_name\n",
    "    \"\"\")\n",
    "    return [row[0] for row in cur.fetchall()]\n",
    "\n",
    "\n",
    "table_names = get_all_tables()\n",
    "table_list_str = \", \".join(table_names)\n",
    "\n",
    "\n",
    "def ensure_table(tablename: str):\n",
    "    query = sql.SQL(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {} (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            context TEXT,\n",
    "            embedding VECTOR({})\n",
    "        )\n",
    "    \"\"\").format(\n",
    "        sql.Identifier(tablename),\n",
    "        sql.SQL(str(EMBED_DIM))\n",
    "    )\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def insert_data(tablename: str, context: str, embedding: list):\n",
    "    query = sql.SQL(\"\"\"\n",
    "        INSERT INTO {} (context, embedding)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\").format(sql.Identifier(tablename))\n",
    "    cur.execute(query, (context, embedding))\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def search_similar(tablename: str, embedding: list, limit: int = 3):\n",
    "    query = sql.SQL(\"\"\"\n",
    "        SELECT context\n",
    "        FROM {}\n",
    "        ORDER BY embedding <=> %s::vector\n",
    "        LIMIT %s\n",
    "    \"\"\").format(sql.Identifier(tablename))\n",
    "    cur.execute(query, (embedding, limit))\n",
    "    return [row[0] for row in cur.fetchall()]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# EMBEDDING\n",
    "# =========================================================\n",
    "def embed_text(text: str) -> list:\n",
    "    res = ollama.embeddings(\n",
    "        model=EMBED_MODEL,\n",
    "        prompt=text\n",
    "    )\n",
    "    return res[\"embedding\"]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# LLM ROUTING\n",
    "# =========================================================\n",
    "def record_data(context: str) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are a strict decision engine.\\n\"\n",
    "        \"If the context clearly matches an existing table, return EXACTLY that table name.\\n\"\n",
    "        \"If not, create ONE new short english table name.\\n\"\n",
    "        \"Return ONLY the table name.\\n\\n\"\n",
    "        f\"Existing tables: {table_list_str}\"\n",
    "    )\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": context},\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "def choose_table_for_question(question: str) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are a semantic router.\\n\"\n",
    "        \"Choose ONE most relevant table for answering the question.\\n\"\n",
    "        \"Return ONLY the table name.\\n\\n\"\n",
    "        f\"Existing tables: {', '.join(table_names)}\"\n",
    "    )\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# QA\n",
    "# =========================================================\n",
    "def answer_question(question: str, contexts: list, language: str) -> str:\n",
    "    joined_context = \"\\n\".join(f\"- {c}\" for c in contexts)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a question answering system.\\n\"\n",
    "        \"Answer ONLY using the provided context.\\n\"\n",
    "        f\"Answer in {language}.\\n\"\n",
    "        \"If the context is insufficient, say you don't know.\"\n",
    "    )\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context:\\n{joined_context}\\n\\nQuestion:\\n{question}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CLI\n",
    "# =========================================================\n",
    "print(\"Select answer language:\")\n",
    "print(\"1 = Thai\")\n",
    "print(\"2 = English\")\n",
    "\n",
    "lang_choice = input(\"Language (1/2): \").strip()\n",
    "answer_language = \"English\" if lang_choice == \"2\" else \"Thai\"\n",
    "\n",
    "print(f\"Answer language set to: {answer_language}\")\n",
    "\n",
    "print(\"\\nChoose mode:\")\n",
    "print(\"1 = Ingest (save memory)\")\n",
    "print(\"2 = Ask (question)\")\n",
    "print(\"Type /bye to exit\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    mode = input(\"\\nMode (1/2): \").strip()\n",
    "\n",
    "    if mode.lower() == \"/bye\":\n",
    "        print(\"Bye üëã\")\n",
    "        break\n",
    "\n",
    "    # -----------------------\n",
    "    # MODE 1: INGEST\n",
    "    # -----------------------\n",
    "    if mode == \"1\":\n",
    "        context = input(\"Context to save: \").strip()\n",
    "        if not context:\n",
    "            continue\n",
    "\n",
    "        table = record_data(context)\n",
    "        print(\"Chosen table:\", table)\n",
    "\n",
    "        if table not in table_names:\n",
    "            ensure_table(table)\n",
    "            table_names.append(table)\n",
    "\n",
    "        embedding = embed_text(context)\n",
    "        insert_data(table, context, embedding)\n",
    "\n",
    "        print(\"Saved ‚úÖ\")\n",
    "\n",
    "    # -----------------------\n",
    "    # MODE 2: ASK\n",
    "    # -----------------------\n",
    "    elif mode == \"2\":\n",
    "        question = input(\"Question: \").strip()\n",
    "        if not question:\n",
    "            continue\n",
    "\n",
    "        table = choose_table_for_question(question)\n",
    "        print(\"Searching in table:\", table)\n",
    "\n",
    "        if table not in table_names:\n",
    "            print(\"No relevant data found ‚ùå\")\n",
    "            continue\n",
    "\n",
    "        q_embedding = embed_text(question)\n",
    "        contexts = search_similar(table, q_embedding)\n",
    "\n",
    "        if not contexts:\n",
    "            print(\"No matching context ‚ùå\")\n",
    "            continue\n",
    "\n",
    "        answer = answer_question(question, contexts, answer_language)\n",
    "        print(\"\\nAnswer:\")\n",
    "        print(answer)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid mode\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CLEANUP\n",
    "# =========================================================\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86769a9c-f558-4c5c-84a6-097c78e9b364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
